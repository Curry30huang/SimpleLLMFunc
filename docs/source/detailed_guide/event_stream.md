# äº‹ä»¶æµç³»ç»Ÿï¼ˆEvent Streamï¼‰

äº‹ä»¶æµæ˜¯ SimpleLLMFunc v0.5.0+ å¼•å…¥çš„é«˜çº§ç‰¹æ€§ï¼Œå…è®¸ä½ å®æ—¶è§‚å¯Ÿ ReAct å¾ªç¯çš„å®Œæ•´æ‰§è¡Œè¿‡ç¨‹ã€‚é€šè¿‡å¯ç”¨äº‹ä»¶æµï¼Œä½ å¯ä»¥ç›‘æ§ LLM è°ƒç”¨ã€å·¥å…·è°ƒç”¨ã€æµå¼å“åº”ç­‰æ‰€æœ‰å…³é”®ç¯èŠ‚ï¼Œå®ç°æ›´ç²¾ç»†çš„æ§åˆ¶å’Œæ›´å¥½çš„ç”¨æˆ·ä½“éªŒã€‚

**é€‚ç”¨èŒƒå›´**ï¼šäº‹ä»¶æµç³»ç»ŸåŒæ—¶æ”¯æŒ `@llm_chat` å’Œ `@llm_function` è£…é¥°å™¨ï¼Œæä¾›ç»Ÿä¸€çš„äº‹ä»¶è§‚æµ‹ä½“éªŒã€‚

## æ¦‚è¿°

### ä»€ä¹ˆæ˜¯äº‹ä»¶æµï¼Ÿ

äº‹ä»¶æµï¼ˆEvent Streamï¼‰æ˜¯ä¸€ç§è§‚å¯Ÿè€…æ¨¡å¼çš„åº”ç”¨ï¼Œå®ƒä¼šåœ¨ ReAct å¾ªç¯æ‰§è¡Œè¿‡ç¨‹ä¸­äº§ç”Ÿä¸€ç³»åˆ—äº‹ä»¶ï¼ŒåŒ…æ‹¬ï¼š

- **LLM è°ƒç”¨äº‹ä»¶**ï¼šLLM è°ƒç”¨å¼€å§‹ã€æµå¼ chunk åˆ°è¾¾ã€è°ƒç”¨ç»“æŸ
- **å·¥å…·è°ƒç”¨äº‹ä»¶**ï¼šå·¥å…·è°ƒç”¨å¼€å§‹ã€æ‰§è¡Œå®Œæˆã€æ‰¹æ¬¡å¤„ç†
- **ReAct å¾ªç¯äº‹ä»¶**ï¼šå¾ªç¯å¼€å§‹ã€è¿­ä»£å¼€å§‹/ç»“æŸã€å¾ªç¯ç»“æŸ
- **æ‰§è¡Œç»Ÿè®¡**ï¼šToken ä½¿ç”¨é‡ã€æ‰§è¡Œè€—æ—¶ã€è°ƒç”¨æ¬¡æ•°ç­‰

### ä¸ºä»€ä¹ˆéœ€è¦äº‹ä»¶æµï¼Ÿ

åœ¨ä¼ ç»Ÿä½¿ç”¨ä¸­ï¼Œä½ åªèƒ½è·å¾—æœ€ç»ˆçš„å“åº”ç»“æœã€‚è€Œäº‹ä»¶æµæä¾›äº†ï¼š

1. **å®æ—¶ç›‘æ§**ï¼šè§‚å¯Ÿ LLM å’Œå·¥å…·è°ƒç”¨çš„å®æ—¶çŠ¶æ€
2. **æ€§èƒ½åˆ†æ**ï¼šè·å–è¯¦ç»†çš„æ‰§è¡Œç»Ÿè®¡å’Œæ€§èƒ½æŒ‡æ ‡ï¼ˆToken ç”¨é‡ã€è€—æ—¶ç­‰ï¼‰
3. **è‡ªå®šä¹‰ UI**ï¼šåŸºäºäº‹ä»¶æ„å»ºä¸°å¯Œçš„ç”¨æˆ·ç•Œé¢ï¼ˆè¿›åº¦æ¡ã€æµå¼æ˜¾ç¤ºç­‰ï¼‰
4. **è°ƒè¯•æ”¯æŒ**ï¼šæ·±å…¥äº†è§£ ReAct å¾ªç¯çš„æ‰§è¡Œç»†èŠ‚
5. **çŠ¶æ€ç®¡ç†**ï¼šé€šè¿‡ Wrapper æ¨¡å¼å®ç° Context Compressionã€çŠ¶æ€æŒä¹…åŒ–ç­‰

### è®¾è®¡å“²å­¦ï¼šAgent ä½œä¸ºæ— çŠ¶æ€å‡½æ•°

SimpleLLMFunc éµå¾ªä¸€ä¸ªæ ¸å¿ƒè®¾è®¡å“²å­¦ï¼š**Agent æœ¬èº«æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œä¸ç®¡ç†è‡ªå·±çš„çŠ¶æ€**ã€‚

è¿™æ„å‘³ç€ï¼š

- âœ… **æ— çŠ¶æ€è®¾è®¡**ï¼š`@llm_chat` è£…é¥°çš„å‡½æ•°æ˜¯çº¯å‡½æ•°ï¼Œæ¯æ¬¡è°ƒç”¨éƒ½æ˜¯ç‹¬ç«‹çš„
- âœ… **çŠ¶æ€å¤–ç½®**ï¼šæ‰€æœ‰çŠ¶æ€ï¼ˆåŒ…æ‹¬ `history`ï¼‰éƒ½é€šè¿‡å‚æ•°ä¼ å…¥å’Œè¿”å›å€¼ä¼ å‡º
- âœ… **å¯ç»„åˆæ€§**ï¼šé€šè¿‡ wrapper å‡½æ•°å®ç°çŠ¶æ€ç®¡ç†å’Œé«˜çº§åŠŸèƒ½

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**

1. **å‡½æ•°å¼ç¼–ç¨‹**ï¼šç¬¦åˆå‡½æ•°å¼ç¼–ç¨‹ç†å¿µï¼Œæ˜“äºæµ‹è¯•å’Œæ¨ç†
2. **çµæ´»æ€§**ï¼šçŠ¶æ€ç®¡ç†å®Œå…¨ç”±ç”¨æˆ·æ§åˆ¶ï¼Œå¯ä»¥å®ç°å„ç§è‡ªå®šä¹‰é€»è¾‘
3. **å¯æ‰©å±•æ€§**ï¼šé€šè¿‡ wrapper å‡½æ•°å¯ä»¥è½»æ¾æ·»åŠ  Context Compressionã€çŠ¶æ€æŒä¹…åŒ–ç­‰åŠŸèƒ½

**å¦‚ä½•å®ç°çŠ¶æ€ç®¡ç†å’Œä¿®æ”¹ï¼Ÿ**

é€šè¿‡äº‹ä»¶æµï¼Œä½ å¯ä»¥ï¼š

1. **ç›‘æ§çŠ¶æ€**ï¼šé€šè¿‡äº‹ä»¶è·å– Agent çš„å†…éƒ¨çŠ¶æ€ä¿¡æ¯ï¼ˆæ¶ˆæ¯å†å²ã€å·¥å…·è°ƒç”¨ç­‰ï¼‰
2. **ä¿®æ”¹çŠ¶æ€**ï¼šåœ¨ wrapper å‡½æ•°ä¸­æ‹¦æˆªå’Œä¿®æ”¹ `history`ï¼Œå®ç° Context Compression ç­‰åŠŸèƒ½
3. **çŠ¶æ€æŒä¹…åŒ–**ï¼šåœ¨ wrapper ä¸­å®ç°çŠ¶æ€çš„ä¿å­˜å’Œæ¢å¤

ä¸‹é¢æˆ‘ä»¬å°†è¯¦ç»†å±•ç¤ºå¦‚ä½•é€šè¿‡ wrapper å‡½æ•°å®ç°è¿™äº›åŠŸèƒ½ã€‚

## å¯ç”¨äº‹ä»¶æµ

### åŸºæœ¬ç”¨æ³•

åœ¨ `@llm_chat` æˆ– `@llm_function` è£…é¥°å™¨ä¸­è®¾ç½® `enable_event=True` å³å¯å¯ç”¨äº‹ä»¶æµï¼š

#### llm_chat çš„äº‹ä»¶æµ

`@llm_chat` è£…é¥°å™¨åœ¨å¯ç”¨äº‹ä»¶æµæ—¶ï¼Œè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œyield `ReactOutput`ï¼š

```python
from SimpleLLMFunc import llm_chat
from SimpleLLMFunc.hooks import ReactOutput, ResponseYield, EventYield

@llm_chat(
    llm_interface=llm,
    toolkit=[calculate, get_weather],
    stream=True,
    enable_event=True,  # ğŸ”‘ å¯ç”¨äº‹ä»¶æµ
)
async def chat(message: str, history=None):
    """æ™ºèƒ½åŠ©æ‰‹"""
    pass

# ä½¿ç”¨äº‹ä»¶æµ
async for output in chat("Hello"):
    if isinstance(output, ResponseYield):
        # å¤„ç†å“åº”æ•°æ®
        print(output.response)
    elif isinstance(output, EventYield):
        # å¤„ç†äº‹ä»¶
        event = output.event
        print(f"äº‹ä»¶ç±»å‹: {event.event_type}")
```

#### llm_function çš„äº‹ä»¶æµ

`@llm_function` è£…é¥°å™¨åœ¨å¯ç”¨äº‹ä»¶æµæ—¶ï¼Œä¹Ÿè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œyield `ReactOutput`ï¼š

```python
from SimpleLLMFunc import llm_function
from SimpleLLMFunc.hooks import ReactOutput, ResponseYield, EventYield

@llm_function(
    llm_interface=llm,
    toolkit=[calculate, get_weather],
    enable_event=True,  # ğŸ”‘ å¯ç”¨äº‹ä»¶æµ
)
async def analyze_text(text: str) -> str:
    """åˆ†ææ–‡æœ¬å†…å®¹"""
    pass

# ä½¿ç”¨äº‹ä»¶æµ
async for output in analyze_text("Hello world"):
    if isinstance(output, ResponseYield):
        # å¤„ç†å“åº”æ•°æ®ï¼ˆæœ€ç»ˆç»“æœï¼‰
        result = output.response
        print(f"åˆ†æç»“æœ: {result}")
    elif isinstance(output, EventYield):
        # å¤„ç†äº‹ä»¶ï¼ˆLLM è°ƒç”¨ã€å·¥å…·è°ƒç”¨ç­‰ï¼‰
        event = output.event
        print(f"äº‹ä»¶: {event.event_type}")
```

### è¿”å›å€¼å˜åŒ–

å¯ç”¨äº‹ä»¶æµåï¼Œå‡½æ•°çš„è¿”å›å€¼ç±»å‹ä¼šå‘ç”Ÿå˜åŒ–ï¼š

**llm_chat é»˜è®¤æ¨¡å¼** (`enable_event=False`):

```python
async for chunk, updated_history in chat("Hello"):
    print(chunk)
```

**llm_chat äº‹ä»¶æµæ¨¡å¼** (`enable_event=True`):

```python
async for output in chat("Hello"):
    if isinstance(output, ResponseYield):
        print(output.response)
    elif isinstance(output, EventYield):
        print(f"äº‹ä»¶: {output.event.event_type}")
```

**llm_function é»˜è®¤æ¨¡å¼** (`enable_event=False`):

```python
result = await analyze_text("Hello")
print(result)
```

**llm_function äº‹ä»¶æµæ¨¡å¼** (`enable_event=True`):

```python
async for output in analyze_text("Hello"):
    if isinstance(output, ResponseYield):
        result = output.response
        print(f"ç»“æœ: {result}")
    elif isinstance(output, EventYield):
        print(f"äº‹ä»¶: {output.event.event_type}")
```

## æ ¸å¿ƒç±»å‹

### ReactOutput

`ReactOutput` æ˜¯ä¸€ä¸ª Tagged Union ç±»å‹ï¼ŒåŒ…å«ä¸¤ç§å¯èƒ½çš„å€¼ï¼š

```python
from SimpleLLMFunc.hooks import ReactOutput, ResponseYield, EventYield

# ReactOutput = ResponseYield | EventYield
```

### ResponseYield

å“åº”æ•°æ®ï¼ŒåŒ…å« LLM çš„å“åº”å†…å®¹å’Œæ¶ˆæ¯å†å²ï¼š

```python
@dataclass
class ResponseYield:
    response: Union[LLMResponse, LLMStreamChunk, str]  # å“åº”å†…å®¹
    messages: MessageList  # æ¶ˆæ¯å†å²
    type: Literal["response"] = "response"
```

### EventYield

äº‹ä»¶æ•°æ®ï¼ŒåŒ…å« ReAct å¾ªç¯ä¸­çš„å„ç§äº‹ä»¶ï¼š

```python
@dataclass
class EventYield:
    event: ReActEvent  # äº‹ä»¶å¯¹è±¡
    type: Literal["event"] = "event"
```

## äº‹ä»¶ç±»å‹

äº‹ä»¶æµåŒ…å«ä»¥ä¸‹ç±»å‹çš„äº‹ä»¶ï¼ŒæŒ‰æ‰§è¡Œé¡ºåºæ’åˆ—ï¼š

### 1. ReactStartEvent

ReAct å¾ªç¯å¼€å§‹äº‹ä»¶ï¼Œåœ¨å¾ªç¯å¼€å§‹æ—¶è§¦å‘ã€‚

```python
@dataclass
class ReactStartEvent(ReActEvent):
    user_task_prompt: str  # ç”¨æˆ·ä»»åŠ¡æç¤º
    initial_messages: MessageList  # åˆå§‹æ¶ˆæ¯åˆ—è¡¨
    available_tools: ToolDefinitionList  # å¯ç”¨å·¥å…·åˆ—è¡¨
```

**ä½¿ç”¨åœºæ™¯**ï¼šåˆå§‹åŒ– UIã€æ˜¾ç¤ºå¼€å§‹æç¤ºã€è®°å½• trace_id

### 2. ReactIterationStartEvent

ReAct è¿­ä»£å¼€å§‹äº‹ä»¶ï¼Œæ¯æ¬¡è¿­ä»£å¼€å§‹æ—¶è§¦å‘ã€‚

```python
@dataclass
class ReactIterationStartEvent(ReActEvent):
    current_messages: MessageList  # å½“å‰æ¶ˆæ¯å†å²
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤ºè¿­ä»£è¿›åº¦ã€æ›´æ–°æ¶ˆæ¯å†å²

### 3. LLMCallStartEvent

LLM è°ƒç”¨å¼€å§‹äº‹ä»¶ï¼Œåœ¨ LLM è°ƒç”¨å‰è§¦å‘ã€‚

```python
@dataclass
class LLMCallStartEvent(ReActEvent):
    messages: MessageList  # æ¶ˆæ¯åˆ—è¡¨
    tools: ToolDefinitionList  # å·¥å…·å®šä¹‰åˆ—è¡¨
    llm_kwargs: Dict[str, Any]  # LLM è°ƒç”¨å‚æ•°
    stream: bool  # æ˜¯å¦æµå¼è°ƒç”¨
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤º"æ­£åœ¨æ€è€ƒ..."æç¤ºã€è®°å½•è°ƒç”¨å‚æ•°

### 4. LLMChunkArriveEvent

LLM æµå¼ chunk åˆ°è¾¾äº‹ä»¶ï¼ˆä»…æµå¼æ¨¡å¼ï¼‰ã€‚

```python
@dataclass
class LLMChunkArriveEvent(ReActEvent):
    chunk: LLMStreamChunk  # LLM è¿”å›çš„ chunk å¯¹è±¡
    accumulated_content: str  # ç´¯ç§¯çš„å†…å®¹
    chunk_index: int  # Chunk åºå·
```

**ä½¿ç”¨åœºæ™¯**ï¼šå®æ—¶æ¸²æŸ“æµå¼å“åº”ã€æ˜¾ç¤ºæ‰“å­—æ•ˆæœ

### 5. LLMCallEndEvent

LLM è°ƒç”¨ç»“æŸäº‹ä»¶ï¼Œåœ¨è°ƒç”¨å®Œæˆåè§¦å‘ã€‚

```python
@dataclass
class LLMCallEndEvent(ReActEvent):
    response: LLMResponse  # LLM å“åº”å¯¹è±¡
    messages: MessageList  # æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
    tool_calls: List[ToolCall]  # æå–çš„å·¥å…·è°ƒç”¨åˆ—è¡¨
    execution_time: float  # æ‰§è¡Œè€—æ—¶
    usage: Optional[LLMUsage]  # Token ä½¿ç”¨ç»Ÿè®¡
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤º Token ä½¿ç”¨é‡ã€è®°å½•æ€§èƒ½æŒ‡æ ‡ã€æ£€æŸ¥å·¥å…·è°ƒç”¨

### 6. ToolCallsBatchStartEvent

å·¥å…·è°ƒç”¨æ‰¹æ¬¡å¼€å§‹äº‹ä»¶ï¼Œå½“ LLM è¿”å›å¤šä¸ªå·¥å…·è°ƒç”¨æ—¶è§¦å‘ã€‚

```python
@dataclass
class ToolCallsBatchStartEvent(ReActEvent):
    tool_calls: List[ToolCall]  # å·¥å…·è°ƒç”¨åˆ—è¡¨
    batch_size: int  # æ‰¹æ¬¡å¤§å°
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤ºå·¥å…·è°ƒç”¨æ‰¹æ¬¡ä¿¡æ¯ã€å‡†å¤‡å¹¶è¡Œæ‰§è¡Œ

### 7. ToolCallStartEvent

å•ä¸ªå·¥å…·è°ƒç”¨å¼€å§‹äº‹ä»¶ã€‚

```python
@dataclass
class ToolCallStartEvent(ReActEvent):
    tool_name: str  # å·¥å…·åç§°
    tool_call_id: str  # å·¥å…·è°ƒç”¨ ID
    arguments: ToolCallArguments  # å·¥å…·è°ƒç”¨å‚æ•°
    tool_call: ToolCall  # å®Œæ•´çš„å·¥å…·è°ƒç”¨å¯¹è±¡
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯ã€è®°å½•è°ƒç”¨å‚æ•°

### 8. ToolCallEndEvent

å•ä¸ªå·¥å…·è°ƒç”¨ç»“æŸäº‹ä»¶ï¼ˆ**å…³é”®**ï¼šç«‹å³è·å–ç»“æœï¼‰ã€‚

```python
@dataclass
class ToolCallEndEvent(ReActEvent):
    tool_name: str  # å·¥å…·åç§°
    tool_call_id: str  # å·¥å…·è°ƒç”¨ ID
    arguments: ToolCallArguments  # å·¥å…·è°ƒç”¨å‚æ•°
    result: ToolResult  # å·¥å…·æ‰§è¡Œç»“æœ
    execution_time: float  # æ‰§è¡Œè€—æ—¶
    success: bool  # æ˜¯å¦æˆåŠŸæ‰§è¡Œ
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤ºå·¥å…·æ‰§è¡Œç»“æœã€æ›´æ–° UIã€è®°å½•æ‰§è¡Œæ—¶é—´

### 9. ToolCallsBatchEndEvent

å·¥å…·è°ƒç”¨æ‰¹æ¬¡ç»“æŸäº‹ä»¶ï¼Œæ‰¹æ¬¡å…¨éƒ¨å®Œæˆåè§¦å‘ã€‚

```python
@dataclass
class ToolCallsBatchEndEvent(ReActEvent):
    tool_results: List[ToolCallResult]  # æ‰€æœ‰å·¥å…·è°ƒç”¨ç»“æœ
    batch_size: int  # æ‰¹æ¬¡å¤§å°
    total_execution_time: float  # æ€»æ‰§è¡Œæ—¶é—´
    success_count: int  # æˆåŠŸæ•°é‡
    error_count: int  # å¤±è´¥æ•°é‡
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤ºæ‰¹æ¬¡ç»Ÿè®¡ã€æ€§èƒ½åˆ†æ

### 10. ReactIterationEndEvent

ReAct è¿­ä»£ç»“æŸäº‹ä»¶ï¼Œæ¯æ¬¡è¿­ä»£å®Œæˆæ—¶è§¦å‘ã€‚

```python
@dataclass
class ReactIterationEndEvent(ReActEvent):
    messages: MessageList  # æ›´æ–°åçš„æ¶ˆæ¯å†å²
    iteration_time: float  # è¿­ä»£è€—æ—¶
    tool_calls_count: int  # æœ¬æ¬¡è¿­ä»£çš„å·¥å…·è°ƒç”¨æ•°é‡
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤ºè¿­ä»£ç»Ÿè®¡ã€æ›´æ–°è¿›åº¦

### 11. ReactEndEvent

ReAct å¾ªç¯ç»“æŸäº‹ä»¶ï¼Œå¾ªç¯ç»“æŸæ—¶è§¦å‘ã€‚

```python
@dataclass
class ReactEndEvent(ReActEvent):
    final_response: str  # æœ€ç»ˆå“åº”å†…å®¹
    final_messages: MessageList  # å®Œæ•´çš„æ¶ˆæ¯å†å²
    total_iterations: int  # æ€»è¿­ä»£æ¬¡æ•°
    total_execution_time: float  # æ€»æ‰§è¡Œæ—¶é—´
    total_tool_calls: int  # æ€»å·¥å…·è°ƒç”¨æ¬¡æ•°
    total_llm_calls: int  # æ€» LLM è°ƒç”¨æ¬¡æ•°
    total_token_usage: Optional[LLMUsage]  # æ€» token ä½¿ç”¨ç»Ÿè®¡
```

**ä½¿ç”¨åœºæ™¯**ï¼šæ˜¾ç¤ºå®Œæ•´ç»Ÿè®¡ã€æ€§èƒ½åˆ†æã€ä¿å­˜æ‰§è¡Œè®°å½•

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: åŸºæœ¬äº‹ä»¶å¤„ç†

```python
import asyncio
from SimpleLLMFunc import llm_chat, tool
from SimpleLLMFunc.hooks import (
    ReactOutput,
    ResponseYield,
    EventYield,
    ReactStartEvent,
    LLMCallStartEvent,
    LLMChunkArriveEvent,
    ToolCallStartEvent,
    ToolCallEndEvent,
    ReactEndEvent,
)

@tool(name="calculate", description="æ‰§è¡Œæ•°å­¦è®¡ç®—")
async def calculate(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    return str(eval(expression))

@llm_chat(
    llm_interface=llm,
    toolkit=[calculate],
    stream=True,
    enable_event=True,
)
async def chat(message: str, history=None):
    """æ™ºèƒ½åŠ©æ‰‹"""
    pass

async def main():
    async for output in chat("å¸®æˆ‘è®¡ç®— 25 * 4 + 18"):
        if isinstance(output, EventYield):
            event = output.event
            
            if isinstance(event, ReactStartEvent):
                print(f"ğŸš€ å¼€å§‹å¤„ç† (trace_id: {event.trace_id[:8]}...)")
            
            elif isinstance(event, LLMCallStartEvent):
                print(f"ğŸ¤– LLM è°ƒç”¨å¼€å§‹ ({'æµå¼' if event.stream else 'éæµå¼'})")
            
            elif isinstance(event, LLMChunkArriveEvent):
                # å®æ—¶æ˜¾ç¤ºæµå¼å“åº”
                chunk_content = event.chunk.choices[0].delta.content
                if chunk_content:
                    print(chunk_content, end="", flush=True)
            
            elif isinstance(event, ToolCallStartEvent):
                print(f"\nğŸ› ï¸  è°ƒç”¨å·¥å…·: {event.tool_name}")
                print(f"   å‚æ•°: {event.arguments}")
            
            elif isinstance(event, ToolCallEndEvent):
                print(f"   âœ… ç»“æœ: {event.result} ({event.execution_time:.2f}s)")
            
            elif isinstance(event, ReactEndEvent):
                print(f"\nğŸ“Š ç»Ÿè®¡:")
                print(f"   æ€»è€—æ—¶: {event.total_execution_time:.2f}s")
                print(f"   LLM è°ƒç”¨: {event.total_llm_calls} æ¬¡")
                print(f"   å·¥å…·è°ƒç”¨: {event.total_tool_calls} æ¬¡")
                if event.total_token_usage:
                    print(f"   Token: {event.total_token_usage.total_tokens}")
        
        elif isinstance(output, ResponseYield):
            # å¤„ç†å“åº”æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            pass

asyncio.run(main())
```

### ç¤ºä¾‹ 2: ä½¿ç”¨ç±»å‹å®ˆå«

```python
from SimpleLLMFunc.hooks import is_response_yield, is_event_yield

async for output in chat("Hello"):
    if is_response_yield(output):
        # TypeScript ä¼šçŸ¥é“ output æ˜¯ ResponseYield
        print(output.response)
    elif is_event_yield(output):
        # TypeScript ä¼šçŸ¥é“ output æ˜¯ EventYield
        print(output.event.event_type)
```

### ç¤ºä¾‹ 3: ä½¿ç”¨è¿‡æ»¤å™¨

```python
from SimpleLLMFunc.hooks import (
    responses_only,
    events_only,
    filter_events,
    ReActEventType,
)

# åªè·å–å“åº”ï¼ˆå‘åå…¼å®¹ï¼‰
async for response, history in responses_only(chat("Hello")):
    print(response)

# åªè·å–äº‹ä»¶
async for event in events_only(chat("Hello")):
    print(f"äº‹ä»¶: {event.event_type}")

# è¿‡æ»¤ç‰¹å®šäº‹ä»¶ç±»å‹
async for event in filter_events(
    chat("æŸ¥è¯¢å¤©æ°”"),
    event_types={ReActEventType.TOOL_CALL_END}
):
    print(f"å·¥å…·è°ƒç”¨å®Œæˆ: {event.tool_name}")
    print(f"ç»“æœ: {event.result}")
```

### ç¤ºä¾‹ 4: äº‹ä»¶è§‚æµ‹å™¨

ä½¿ç”¨ `@with_event_observer` è£…é¥°å™¨è‡ªåŠ¨å¤„ç†æ‰€æœ‰äº‹ä»¶ï¼š

```python
from SimpleLLMFunc.hooks import with_event_observer

async def log_event(event: ReActEvent):
    """è®°å½•æ‰€æœ‰äº‹ä»¶åˆ°æ—¥å¿—ç³»ç»Ÿ"""
    print(f"[{event.timestamp}] {event.event_type}: {event.func_name}")

@with_event_observer(log_event)
@llm_chat(llm_interface=llm, enable_event=True)
async def observed_chat(message: str, history=None):
    """å¸¦äº‹ä»¶è§‚æµ‹çš„èŠå¤©"""
    pass

# ä½¿ç”¨
async for output in observed_chat("Hello"):
    # æ‰€æœ‰äº‹ä»¶éƒ½ä¼šè‡ªåŠ¨è¢« log_event å¤„ç†
    if is_response_yield(output):
        print(output.response)
```

### ç¤ºä¾‹ 5: å®Œæ•´çš„äº‹ä»¶æµ Chatbot

å‚è€ƒ [examples/event_stream_chatbot.py](https://github.com/NiJingzhe/SimpleLLMFunc/blob/master/examples/event_stream_chatbot.py) è·å–ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„ç¤ºä¾‹ï¼ŒåŒ…æ‹¬ï¼š

- å®æ—¶æµå¼å“åº”æ¸²æŸ“ï¼ˆä½¿ç”¨ Rich åº“ï¼‰
- å·¥å…·è°ƒç”¨å¯è§†åŒ–
- å®Œæ•´çš„æ‰§è¡Œç»Ÿè®¡
- ç¾è§‚çš„ç»ˆç«¯ UI

## æœ€ä½³å®è·µ

### 1. äº‹ä»¶å¤„ç†é¡ºåº

äº‹ä»¶æŒ‰ç…§ ReAct å¾ªç¯çš„æ‰§è¡Œé¡ºåºäº§ç”Ÿï¼Œå»ºè®®æŒ‰ç…§ä»¥ä¸‹é¡ºåºå¤„ç†ï¼š

```text
ReactStartEvent
  â†’ ReactIterationStartEvent
    â†’ LLMCallStartEvent
      â†’ LLMChunkArriveEvent (æµå¼æ¨¡å¼)
      â†’ LLMCallEndEvent
    â†’ ToolCallsBatchStartEvent (å¦‚æœæœ‰å·¥å…·è°ƒç”¨)
      â†’ ToolCallStartEvent
      â†’ ToolCallEndEvent
      â†’ ...
    â†’ ToolCallsBatchEndEvent
  â†’ ReactIterationEndEvent
  â†’ (é‡å¤è¿­ä»£...)
â†’ ReactEndEvent
```

### 2. æ€§èƒ½è€ƒè™‘

- äº‹ä»¶å¤„ç†åº”è¯¥æ˜¯è½»é‡çº§çš„ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
- ä½¿ç”¨å¼‚æ­¥æ“ä½œå¤„ç†äº‹ä»¶ï¼ˆå¦‚æ—¥å¿—è®°å½•ã€UI æ›´æ–°ï¼‰
- å¯¹äºé«˜é¢‘äº‹ä»¶ï¼ˆå¦‚ `LLMChunkArriveEvent`ï¼‰ï¼Œè€ƒè™‘æ‰¹é‡å¤„ç†

### 3. é”™è¯¯å¤„ç†

äº‹ä»¶å¤„ç†ä¸­çš„é”™è¯¯ä¸åº”å½±å“ä¸»æµç¨‹ï¼š

```python
async for output in chat("Hello"):
    if is_event_yield(output):
        try:
            # å¤„ç†äº‹ä»¶
            handle_event(output.event)
        except Exception as e:
            # è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æµç¨‹
            logger.error(f"äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
```

### 4. UI æ›´æ–°

ä½¿ç”¨äº‹ä»¶æµæ„å»ºå“åº”å¼ UIï¼š

```python
class ChatUI:
    def __init__(self):
        self.response_text = ""
        self.tool_calls = []
    
    async def handle_event(self, event: ReActEvent):
        if isinstance(event, LLMChunkArriveEvent):
            # å®æ—¶æ›´æ–°å“åº”æ–‡æœ¬
            self.response_text = event.accumulated_content
            self.update_ui()
        
        elif isinstance(event, ToolCallEndEvent):
            # æ›´æ–°å·¥å…·è°ƒç”¨åˆ—è¡¨
            self.tool_calls.append({
                "name": event.tool_name,
                "result": event.result,
            })
            self.update_ui()
```

### 5. çŠ¶æ€ç®¡ç†å’Œä¿®æ”¹ï¼ˆWrapper æ¨¡å¼ï¼‰

ç”±äº Agent æ˜¯æ— çŠ¶æ€çš„ï¼Œæ‰€æœ‰çŠ¶æ€éƒ½é€šè¿‡å‚æ•°å’Œè¿”å›å€¼ä¼ é€’ã€‚é€šè¿‡ wrapper å‡½æ•°ï¼Œä½ å¯ä»¥ï¼š

- **ç›‘æ§çŠ¶æ€**ï¼šé€šè¿‡äº‹ä»¶è·å–å†…éƒ¨çŠ¶æ€
- **ä¿®æ”¹çŠ¶æ€**ï¼šæ‹¦æˆªå’Œä¿®æ”¹ `history` å‚æ•°
- **å®ç°é«˜çº§åŠŸèƒ½**ï¼šContext Compressionã€çŠ¶æ€æŒä¹…åŒ–ç­‰

#### 5.1 åŸºç¡€ Wrapperï¼šçŠ¶æ€ç›‘æ§

```python
from typing import List, Dict, Any
from SimpleLLMFunc.hooks import ReactOutput, ResponseYield, EventYield, ReactEndEvent

def with_state_monitoring(chat_func):
    """Wrapperï¼šç›‘æ§ Agent çš„çŠ¶æ€å˜åŒ–"""
    async def wrapper(message: str, history: List[Dict[str, str]] = None):
        # è®°å½•åˆå§‹çŠ¶æ€
        initial_history_length = len(history) if history else 0
        print(f"åˆå§‹å†å²é•¿åº¦: {initial_history_length}")
        
        # ä»£ç†è°ƒç”¨
        async for output in chat_func(message, history):
            if isinstance(output, EventYield):
                event = output.event
                
                # ç›‘æ§çŠ¶æ€å˜åŒ–
                if isinstance(event, ReactEndEvent):
                    print(f"æœ€ç»ˆå†å²é•¿åº¦: {len(event.final_messages)}")
                    print(f"æ€»è¿­ä»£æ¬¡æ•°: {event.total_iterations}")
                    print(f"æ€»å·¥å…·è°ƒç”¨: {event.total_tool_calls}")
            
            yield output
    
    return wrapper

# ä½¿ç”¨
@llm_chat(llm_interface=llm, enable_event=True)
async def chat(message: str, history=None):
    """æ™ºèƒ½åŠ©æ‰‹"""
    pass

# åŒ…è£…å‡½æ•°
monitored_chat = with_state_monitoring(chat)

# ä½¿ç”¨åŒ…è£…åçš„å‡½æ•°
async for output in monitored_chat("Hello", history=[]):
    if isinstance(output, ResponseYield):
        print(output.response)
```

#### 5.2 é«˜çº§ Wrapperï¼šContext Compression

é€šè¿‡ä¿®æ”¹ `history` å‚æ•°ï¼Œå¯ä»¥å®ç° Context Compressionï¼ˆä¸Šä¸‹æ–‡å‹ç¼©ï¼‰ï¼š

```python
from typing import List, Dict, Optional
from SimpleLLMFunc.hooks import ResponseYield, EventYield
from copy import deepcopy

def with_context_compression(
    chat_func,
    max_history_length: int = 10,
    compression_strategy: str = "keep_recent"
):
    """
    Wrapperï¼šå®ç°ä¸Šä¸‹æ–‡å‹ç¼©
    
    Args:
        chat_func: åŸå§‹çš„ chat å‡½æ•°
        max_history_length: æœ€å¤§å†å²é•¿åº¦
        compression_strategy: å‹ç¼©ç­–ç•¥ï¼ˆ"keep_recent" æˆ– "keep_important"ï¼‰
    """
    def compress_history(history: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """å‹ç¼©å†å²è®°å½•"""
        if not history or len(history) <= max_history_length:
            return history
        
        if compression_strategy == "keep_recent":
            # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
            return history[-max_history_length:]
        elif compression_strategy == "keep_important":
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„æ¶ˆæ¯
            system_messages = [msg for msg in history if msg.get("role") == "system"]
            recent_messages = history[-max_history_length:]
            # å»é‡ï¼ˆå¦‚æœç³»ç»Ÿæ¶ˆæ¯å·²ç»åœ¨æœ€è¿‘æ¶ˆæ¯ä¸­ï¼‰
            combined = system_messages + recent_messages
            seen = set()
            result = []
            for msg in combined:
                msg_id = id(msg)  # ä½¿ç”¨å¯¹è±¡ ID å»é‡
                if msg_id not in seen:
                    seen.add(msg_id)
                    result.append(msg)
            return result
        else:
            return history[-max_history_length:]
    
    async def wrapper(message: str, history: List[Dict[str, str]] = None):
        # å‹ç¼©è¾“å…¥çš„å†å²è®°å½•
        compressed_history = compress_history(history or [])
        
        # ä»£ç†è°ƒç”¨
        async for output in chat_func(message, compressed_history):
            if isinstance(output, ResponseYield):
                # å‹ç¼©è¿”å›çš„å†å²è®°å½•
                compressed_messages = compress_history(output.messages)
                
                # åˆ›å»ºæ–°çš„ ResponseYieldï¼ŒåŒ…å«å‹ç¼©åçš„å†å²
                yield ResponseYield(
                    response=output.response,
                    messages=compressed_messages
                )
            else:
                yield output
    
    return wrapper

# ä½¿ç”¨
@llm_chat(llm_interface=llm, enable_event=True)
async def chat(message: str, history=None):
    """æ™ºèƒ½åŠ©æ‰‹"""
    pass

# åŒ…è£…å‡½æ•°ï¼ˆæœ€å¤šä¿ç•™ 10 æ¡å†å²ï¼‰
compressed_chat = with_context_compression(chat, max_history_length=10)

# ä½¿ç”¨
async for output in compressed_chat("Hello", history=long_history):
    if isinstance(output, ResponseYield):
        print(output.response)
```

#### 5.3 é«˜çº§ Wrapperï¼šçŠ¶æ€æŒä¹…åŒ–

```python
import json
from pathlib import Path
from typing import List, Dict, Optional

def with_state_persistence(chat_func, state_file: str = "chat_state.json"):
    """
    Wrapperï¼šå®ç°çŠ¶æ€æŒä¹…åŒ–
    
    è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤å¯¹è¯å†å²
    """
    state_path = Path(state_file)
    
    async def wrapper(message: str, history: List[Dict[str, str]] = None):
        # æ¢å¤çŠ¶æ€
        if history is None and state_path.exists():
            try:
                with open(state_path, 'r', encoding='utf-8') as f:
                    history = json.load(f)
                print(f"å·²æ¢å¤å†å²è®°å½•: {len(history)} æ¡æ¶ˆæ¯")
            except Exception as e:
                print(f"æ¢å¤çŠ¶æ€å¤±è´¥: {e}")
                history = []
        
        # ä»£ç†è°ƒç”¨
        final_history = history or []
        async for output in chat_func(message, history):
            if isinstance(output, ResponseYield):
                # æ›´æ–°å†å²
                final_history = output.messages
                
                # ä¿å­˜çŠ¶æ€
                try:
                    with open(state_path, 'w', encoding='utf-8') as f:
                        json.dump(final_history, f, ensure_ascii=False, indent=2)
                except Exception as e:
                    print(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")
            
            yield output
    
    return wrapper

# ä½¿ç”¨
@llm_chat(llm_interface=llm, enable_event=True)
async def chat(message: str, history=None):
    """æ™ºèƒ½åŠ©æ‰‹"""
    pass

# åŒ…è£…å‡½æ•°
persistent_chat = with_state_persistence(chat, "my_chat_state.json")

# ä½¿ç”¨ï¼ˆè‡ªåŠ¨ä¿å­˜å’Œæ¢å¤ï¼‰
async for output in persistent_chat("Hello"):
    if isinstance(output, ResponseYield):
        print(output.response)
```

#### 5.4 ç»„åˆå¤šä¸ª Wrapper

ä½ å¯ä»¥ç»„åˆå¤šä¸ª wrapper å®ç°å¤æ‚çš„åŠŸèƒ½ï¼š

```python
# ç»„åˆå¤šä¸ª wrapper
@llm_chat(llm_interface=llm, enable_event=True)
async def chat(message: str, history=None):
    """æ™ºèƒ½åŠ©æ‰‹"""
    pass

# ç»„åˆï¼šç›‘æ§ + å‹ç¼© + æŒä¹…åŒ–
enhanced_chat = with_state_persistence(
    with_context_compression(
        with_state_monitoring(chat),
        max_history_length=10
    ),
    state_file="chat_state.json"
)

# ä½¿ç”¨
async for output in enhanced_chat("Hello"):
    if isinstance(output, ResponseYield):
        print(output.response)
```

### 6. å‘åå…¼å®¹

å¦‚æœéœ€è¦åŒæ—¶æ”¯æŒäº‹ä»¶æµå’Œä¼ ç»Ÿæ¨¡å¼ï¼Œå¯ä»¥ä½¿ç”¨ `responses_only`ï¼š

```python
# å¯ç”¨äº‹ä»¶æµä½†åªå¤„ç†å“åº”
@llm_chat(llm_interface=llm, enable_event=True)
async def chat(message: str, history=None):
    pass

# ä½¿ç”¨ responses_only è·å¾—ä¼ ç»Ÿ API
async for response, history in responses_only(chat("Hello")):
    print(response)
```

## å¸¸è§é—®é¢˜

### Q: äº‹ä»¶æµä¼šå½±å“æ€§èƒ½å—ï¼Ÿ

A: äº‹ä»¶æµæœ¬èº«æ˜¯è½»é‡çº§çš„ï¼Œä¸ä¼šæ˜¾è‘—å½±å“æ€§èƒ½ã€‚äº‹ä»¶å¤„ç†æ˜¯å¼‚æ­¥çš„ï¼Œä¸ä¼šé˜»å¡ä¸»æµç¨‹ã€‚å¦‚æœä½ æ‹…å¿ƒæ€§èƒ½ï¼Œå¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¦ç”¨äº‹ä»¶æµï¼ˆ`enable_event=False`ï¼‰ã€‚

### Q: å¦‚ä½•åªç›‘å¬ç‰¹å®šç±»å‹çš„äº‹ä»¶ï¼Ÿ

A: ä½¿ç”¨ `filter_events` å‡½æ•°ï¼š

```python
async for event in filter_events(
    chat("Hello"),
    event_types={ReActEventType.TOOL_CALL_END}
):
    # åªå¤„ç†å·¥å…·è°ƒç”¨ç»“æŸäº‹ä»¶
    pass
```

### Q: äº‹ä»¶æµå’Œæµå¼å“åº”æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

A:

- **æµå¼å“åº”** (`stream=True`)ï¼šæ§åˆ¶ LLM æ˜¯å¦ä»¥æµå¼æ–¹å¼è¿”å›å“åº”
- **äº‹ä»¶æµ** (`enable_event=True`)ï¼šæ§åˆ¶æ˜¯å¦äº§ç”Ÿäº‹ä»¶ï¼Œç”¨äºè§‚å¯Ÿæ‰§è¡Œè¿‡ç¨‹

ä¸¤è€…å¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥åŒæ—¶å¯ç”¨ã€‚

### Q: å¯ä»¥åœ¨äº‹ä»¶å¤„ç†ä¸­ä¿®æ”¹æ‰§è¡Œæµç¨‹å—ï¼Ÿ

A: äº‹ä»¶æ˜¯åªè¯»çš„è§‚å¯Ÿç‚¹ï¼Œä¸èƒ½ç›´æ¥ä¿®æ”¹æ‰§è¡Œæµç¨‹ã€‚ä½†ä½ å¯ä»¥é€šè¿‡ wrapper å‡½æ•°åœ¨è°ƒç”¨å‰åä¿®æ”¹ `history` å‚æ•°ï¼Œä»è€Œé—´æ¥å½±å“ Agent çš„è¡Œä¸ºã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å®ç° Context Compressionã€çŠ¶æ€è¿‡æ»¤ç­‰åŠŸèƒ½ã€‚

### Q: å¦‚ä½•ä¿®æ”¹ Agent çš„çŠ¶æ€ï¼Ÿ

A: ç”±äº Agent æ˜¯æ— çŠ¶æ€çš„ï¼Œæ‰€æœ‰çŠ¶æ€éƒ½é€šè¿‡ `history` å‚æ•°ä¼ é€’ã€‚ä½ å¯ä»¥ï¼š

1. **åœ¨è°ƒç”¨å‰ä¿®æ”¹**ï¼šé€šè¿‡ wrapper å‡½æ•°ä¿®æ”¹ä¼ å…¥çš„ `history` å‚æ•°
2. **åœ¨è°ƒç”¨åä¿®æ”¹**ï¼šé€šè¿‡ wrapper å‡½æ•°ä¿®æ”¹è¿”å›çš„ `history`ï¼ˆåœ¨ `ResponseYield` ä¸­ï¼‰
3. **é€šè¿‡äº‹ä»¶ç›‘æ§**ï¼šé€šè¿‡äº‹ä»¶è·å–çŠ¶æ€ä¿¡æ¯ï¼Œä½†ä¿®æ”¹éœ€è¦é€šè¿‡ wrapper å®ç°

è¯¦è§ [çŠ¶æ€ç®¡ç†å’Œä¿®æ”¹ï¼ˆWrapper æ¨¡å¼ï¼‰](#5-çŠ¶æ€ç®¡ç†å’Œä¿®æ”¹wrapper-æ¨¡å¼) ç« èŠ‚ã€‚

### Q: llm_function æ”¯æŒäº‹ä»¶æµå—ï¼Ÿ

A: æ˜¯çš„ï¼`@llm_function` ä¹Ÿæ‰§è¡Œ ReAct å¾ªç¯ï¼Œä» v0.5.0+ å¼€å§‹å®Œå…¨æ”¯æŒäº‹ä»¶æµã€‚å½“ `enable_event=True` æ—¶ï¼Œ`@llm_function` è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œyield äº‹ä»¶å’Œæœ€ç»ˆå“åº”ã€‚

**é‡è¦åŒºåˆ«**ï¼š`@llm_function` çš„ `ResponseYield.response` åŒ…å«çš„æ˜¯**è§£æåçš„ç»“æœ**ï¼ˆ`str`ã€Pydantic å¯¹è±¡ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯åŸå§‹çš„ `ChatCompletion` å¯¹è±¡ã€‚è¿™ç¬¦åˆ `llm_function` çš„è®¾è®¡ç†å¿µï¼šå°† LLM å“åº”è½¬æ¢ä¸ºæŒ‡å®šçš„è¿”å›ç±»å‹ã€‚

ç¤ºä¾‹ï¼š

```python
from SimpleLLMFunc import llm_function
from SimpleLLMFunc.hooks.stream import is_response_yield

@llm_function(llm_interface=llm, enable_event=True)
async def summarize(text: str) -> str:
    """ç”Ÿæˆæ‘˜è¦"""
    pass

async for output in summarize(text="..."):
    if is_response_yield(output):
        # output.response æ˜¯è§£æåçš„å­—ç¬¦ä¸²ï¼Œä¸æ˜¯ ChatCompletion
        print(output.response)  # ç›´æ¥æ˜¯æ‘˜è¦æ–‡æœ¬
```

å‚è€ƒç¤ºä¾‹ï¼š

- [Token ç”¨é‡ç›‘æ§](https://github.com/NiJingzhe/SimpleLLMFunc/blob/master/examples/llm_function_token_usage.py) - å­—ç¬¦ä¸²è¿”å›ç±»å‹
- [Pydantic ç»“æ„åŒ–è¾“å‡º](https://github.com/NiJingzhe/SimpleLLMFunc/blob/master/examples/llm_function_event_pydantic.py) - Pydantic å¯¹è±¡è¿”å›ç±»å‹

### Q: äº‹ä»¶ä¸­çš„ `trace_id` æœ‰ä»€ä¹ˆç”¨ï¼Ÿ

A: `trace_id` ç”¨äºè¿½è¸ªæ•´ä¸ª ReAct å¾ªç¯çš„æ‰§è¡Œè¿‡ç¨‹ï¼Œå¯ä»¥ç”¨äºæ—¥å¿—å…³è”ã€è°ƒè¯•å’Œæ€§èƒ½åˆ†æã€‚

## ç›¸å…³èµ„æº

- [llm_chat è£…é¥°å™¨æ–‡æ¡£](llm_chat.md) - äº†è§£ `llm_chat` çš„åŸºç¡€ç”¨æ³•
- [äº‹ä»¶æµ Chatbot ç¤ºä¾‹](https://github.com/NiJingzhe/SimpleLLMFunc/blob/master/examples/event_stream_chatbot.py) - å®Œæ•´ç¤ºä¾‹ä»£ç 
- [å·¥å…·ç³»ç»Ÿæ–‡æ¡£](../tool.md) - äº†è§£å·¥å…·è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯
